{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4133f423",
   "metadata": {},
   "source": [
    "# Laborator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ad306",
   "metadata": {},
   "source": [
    "**Sarcină:** Dezbateți și adnotați rezolvările problemelor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c947c5",
   "metadata": {},
   "source": [
    "## Regresie polinomială"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d52c8",
   "metadata": {},
   "source": [
    "Un magazin de înghețată vrea să prezică vânzările zilnice în funcție de temperatură.\n",
    "\n",
    "Date:\n",
    "- Temperatură (&deg;C): `[15, 18, 20, 22, 25, 27, 30, 32, 35, 37, 40]`\n",
    "- Vânzări (unități): `[20, 35, 50, 70, 100, 130, 170, 190, 220, 235, 250]`\n",
    "\n",
    "Sarcini:\n",
    "1. Vizualizarea datelor (linear vs curved)\n",
    "2. Antrenarea modelelor de regresie polinomială de grad 1, 2 și 3\n",
    "3. Calculare MAE, MSE, RMSE și R<sup>2</sup>\n",
    "4. Determinare ce temperatură e optimă\n",
    "5. Predicție pentru 28&deg;C\n",
    "6. Discuție overfitting vs underfitting"
   ]
  },
  {
   "cell_type": "code",
   "id": "397367ed",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "temperature = np.array([15, 18, 20, 22, 25, 27, 30, 32, 35, 37, 40]).reshape(-1, 1)\n",
    "sales = np.array([20, 35, 50, 70, 100, 130, 170, 190, 220, 235, 250])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(temperature, sales, color='blue', s=50)\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Sales (units)')\n",
    "plt.title('Original Data')\n",
    "plt.grid(True)\n",
    "\n",
    "degrees = [1, 2, 3]\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "for degree in degrees:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(temperature)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, sales)\n",
    "    models[degree] = (poly, model)\n",
    "\n",
    "    y_pred = model.predict(X_poly)\n",
    "    predictions[degree] = y_pred\n",
    "\n",
    "    mae = mean_absolute_error(sales, y_pred)\n",
    "    mse = mean_squared_error(sales, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(sales, y_pred)\n",
    "\n",
    "    print(f\"\\n=== Polynomial Degree {degree} ===\")\n",
    "    print(f\"MAE:  {mae:.2f}\")\n",
    "    print(f\"MSE:  {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²:   {r2:.4f}\")\n",
    "\n",
    "    print(f\"Coefficients: {model.coef_}\")\n",
    "    print(f\"Intercept: {model.intercept_:.2f}\")\n",
    "\n",
    "    temp_range = np.linspace(15, 40, 100).reshape(-1, 1)\n",
    "    X_poly_range = poly.transform(temp_range)\n",
    "    y_range = model.predict(X_poly_range)\n",
    "\n",
    "    plt.subplot(1, 3, degree)\n",
    "    plt.scatter(temperature, sales, color='blue', s=50, label='Data')\n",
    "    plt.plot(temp_range, y_range, color='red', linewidth=2, label=f'Degree {degree}')\n",
    "    plt.xlabel('Temperature (°C)')\n",
    "    plt.ylabel('Sales (units)')\n",
    "    plt.title(f'Degree {degree} (R²={r2:.4f})')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "print(\"\\n=== Prediction for 28°C ===\")\n",
    "for degree in degrees:\n",
    "    poly, model = models[degree]\n",
    "    temp_28 = poly.transform([[28]])\n",
    "    pred_28 = model.predict(temp_28)[0]\n",
    "    print(f\"Degree {degree}: {pred_28:.2f} units\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13ac699b",
   "metadata": {},
   "source": [
    "## Regresie logistică"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2beccb9",
   "metadata": {},
   "source": [
    "Dorim să prezicem dacă un student va promova un examen în funcție de orele de studiu.\n",
    "\n",
    "Date:\n",
    "- Ore studiate: `[1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10]`\n",
    "- Promovat (1=Da, 0=Nu) : `[0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]`\n",
    "\n",
    "Sarcini:\n",
    "1. Vizualizarea datelor\n",
    "2. Antrenarea modelelor de regresie logistică\n",
    "3. Trasarea curbei sigmoid\n",
    "4. Calcularea matricii de confuzie, acurateții, preciziei, recall-ului și scorului F1\n",
    "5. Predicție pentru un student care a studiat 4 ore\n",
    "6. Găsirea orelor de studiu necesare pentru 90% șanse de a promova"
   ]
  },
  {
   "cell_type": "code",
   "id": "46b3bd1d",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "hours = np.array([1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10]).reshape(-1, 1)\n",
    "passed = np.array([0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(hours, passed, color='blue', s=100, alpha=0.6, edgecolors='black', linewidths=1.5)\n",
    "plt.xlabel('Hours Studied', fontsize=12)\n",
    "plt.ylabel('Passed (0=No, 1=Yes)', fontsize=12)\n",
    "plt.title('Student Exam Results', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.yticks([0, 1], ['Failed', 'Passed'])\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(hours, passed)\n",
    "\n",
    "b0 = model.intercept_[0]\n",
    "b1 = model.coef_[0][0]\n",
    "print(f\"Model Coefficients:\")\n",
    "print(f\"  Intercept (b0): {b0:.4f}\")\n",
    "print(f\"  Coefficient (b1): {b1:.4f}\")\n",
    "print(f\"\\nModel equation: P(pass) = 1 / (1 + e^(-({b0:.4f} + {b1:.4f} * hours)))\")\n",
    "\n",
    "hours_range = np.linspace(0, 11, 300).reshape(-1, 1)\n",
    "probabilities = model.predict_proba(hours_range)[:, 1]\n",
    "\n",
    "y_pred = model.predict(hours)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(hours, passed, color='blue', s=100, alpha=0.6, label='Actual',\n",
    "            edgecolors='black', linewidths=1.5, zorder=3)\n",
    "plt.plot(hours_range, probabilities, color='red', linewidth=3, label='Sigmoid curve', zorder=2)\n",
    "plt.axhline(y=0.5, color='green', linestyle='--', linewidth=2, label='Decision boundary (0.5)', zorder=1)\n",
    "plt.xlabel('Hours Studied', fontsize=12)\n",
    "plt.ylabel('Probability of Passing', fontsize=12)\n",
    "plt.title('Logistic Regression Model', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(passed, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"\\n                Predicted\")\n",
    "print(f\"              Fail (0)  Pass (1)\")\n",
    "print(f\"Actual Fail    {tn:4d}      {fp:4d}\")\n",
    "print(f\"Actual Pass    {fn:4d}      {tp:4d}\")\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['Predicted Fail', 'Predicted Pass'],\n",
    "            yticklabels=['Actual Fail', 'Actual Pass'],\n",
    "            annot_kws={\"size\": 16})\n",
    "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Actual Class', fontsize=12)\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(passed, y_pred)\n",
    "precision = precision_score(passed, y_pred)\n",
    "recall = recall_score(passed, y_pred)\n",
    "f1 = f1_score(passed, y_pred)\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"True Positives (TP):   {tp}\")\n",
    "print(f\"True Negatives (TN):   {tn}\")\n",
    "print(f\"False Positives (FP):  {fp}\")\n",
    "print(f\"False Negatives (FN):  {fn}\")\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision * 100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall * 100:.2f}%)\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"INTERPRETATION\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"Accuracy:  {accuracy * 100:.2f}% of all predictions are correct\")\n",
    "print(f\"Precision: {precision * 100:.2f}% of predicted passes are actual passes\")\n",
    "print(f\"Recall:    {recall * 100:.2f}% of actual passes were correctly identified\")\n",
    "print(f\"F1-Score:  {f1:.4f} (harmonic mean of precision and recall)\")\n",
    "\n",
    "hours_4 = np.array([[4]])\n",
    "prob_4 = model.predict_proba(hours_4)[0, 1]\n",
    "pred_4 = model.predict(hours_4)[0]\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"PREDICTION FOR 4 HOURS OF STUDY\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"Probability of passing: {prob_4:.4f} ({prob_4 * 100:.2f}%)\")\n",
    "print(f\"Prediction: {'PASS' if pred_4 == 1 else 'FAIL'}\")\n",
    "\n",
    "hours_90 = (np.log(0.9 / 0.1) - b0) / b1\n",
    "prob_90_check = model.predict_proba([[hours_90]])[0, 1]\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"HOURS NEEDED FOR 90% PASS PROBABILITY\")\n",
    "print(f\"{'=' * 50}\")\n",
    "print(f\"Hours needed: {hours_90:.2f}\")\n",
    "print(f\"Verification: {prob_90_check:.4f} ({prob_90_check * 100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(\"PASS PROBABILITIES FOR DIFFERENT STUDY HOURS\")\n",
    "print(f\"{'=' * 50}\")\n",
    "for h in [2, 4, 6, 8]:\n",
    "    prob = model.predict_proba([[h]])[0, 1]\n",
    "    print(f\"{h} hours: {prob:.4f} ({prob * 100:.2f}%)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fe0413b2",
   "metadata": {},
   "source": [
    "## Clasificator Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f1269",
   "metadata": {},
   "source": [
    "Prezicerea posibilității practicării sporturilor în funcție de vreme (din curs).\n",
    "\n",
    "Date:\n",
    "|Nr| Vreme | Temperatură | Umiditate | Vânt | Joc |\n",
    "|--|---------|------------|----------|------|------|\n",
    "|1| Soare | Mare | Mare | Absent | Nu |\n",
    "|2| Soare | Mare | Mare | Prezent | Nu |\n",
    "|3| înnorat | Mare | Mare | Absent | Da |\n",
    "|4| Ploaie | Medie | Mare | Absent | Da |\n",
    "|5| Ploaie | Mica | Normal | Absent | Da |\n",
    "|6| Ploaie | Mica | Normal | Prezent | Nu |\n",
    "|7| înnorat | Mica | Normal | Prezent | Da |\n",
    "|8| Soare | Medie | Mare | Absent | Nu |\n",
    "|9| Soare | Mica | Normal | Absent | Da |\n",
    "|10| Ploaie | Medie | Normal | Absent | Da |\n",
    "|11| Soare | Medie | Normal | Prezent | Da |\n",
    "|12| înnorat | Medie | Mare | Prezent | Da |\n",
    "|13| înnorat | Mare | Normal | Absent | Da |\n",
    "|14| Ploaie | Medie | Mare | Prezent | Nu |\n",
    "\n",
    "Predicție nouă: Vreme=Soare, Temperatură=Mare, Umiditate=Normală, Vânt=Absent\n",
    "\n",
    "Sarcini:\n",
    "1. Calculare prior posibility P(Play=Yes) și P(Play=No)\n",
    "2. Calculare probabilități condiționale pentru fiecare atribut\n",
    "3. Aplicare formulă Naive Bayes\n",
    "4. Caculare predicții și afișare probabilități\n",
    "5. Calculare matrice de confuzie și toate metricile folosind datele de antrenament\n",
    "6. Discuție Laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac2d904a",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = {\n",
    "    'Weather': ['Sunny', 'Sunny', 'Cloudy', 'Rain', 'Rain', 'Rain', 'Cloudy',\n",
    "                'Sunny', 'Sunny', 'Rain', 'Sunny', 'Cloudy', 'Cloudy', 'Rain'],\n",
    "    'Temperature': ['High', 'High', 'High', 'Medium', 'Low', 'Low', 'Low',\n",
    "                    'Medium', 'Low', 'Medium', 'Medium', 'Medium', 'High', 'Medium'],\n",
    "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal',\n",
    "                 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
    "    'Wind': ['No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes',\n",
    "             'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n",
    "    'Play': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes',\n",
    "             'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nTotal instances: {len(df)}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"MANUAL CALCULATION (Following PDF Method)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "play_yes = df[df['Play'] == 'Yes']\n",
    "play_no = df[df['Play'] == 'No']\n",
    "total = len(df)\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Play = Yes: {len(play_yes)} instances\")\n",
    "print(f\"  Play = No:  {len(play_no)} instances\")\n",
    "\n",
    "p_yes = len(play_yes) / total\n",
    "p_no = len(play_no) / total\n",
    "\n",
    "print(f\"\\n1. PRIOR PROBABILITIES:\")\n",
    "print(f\"   P(Play=Yes) = {len(play_yes)}/{total} = {p_yes:.4f}\")\n",
    "print(f\"   P(Play=No)  = {len(play_no)}/{total} = {p_no:.4f}\")\n",
    "\n",
    "new_instance = {\n",
    "    'Weather': 'Sunny',\n",
    "    'Temperature': 'High',\n",
    "    'Humidity': 'Normal',\n",
    "    'Wind': 'No'\n",
    "}\n",
    "\n",
    "print(f\"\\n2. NEW INSTANCE TO CLASSIFY:\")\n",
    "for key, value in new_instance.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\n3. CONDITIONAL PROBABILITIES for Play=Yes:\")\n",
    "p_sunny_yes = len(play_yes[play_yes['Weather'] == 'Sunny']) / len(play_yes)\n",
    "p_high_yes = len(play_yes[play_yes['Temperature'] == 'High']) / len(play_yes)\n",
    "p_normal_yes = len(play_yes[play_yes['Humidity'] == 'Normal']) / len(play_yes)\n",
    "p_no_wind_yes = len(play_yes[play_yes['Wind'] == 'No']) / len(play_yes)\n",
    "\n",
    "print(f\"   P(Sunny|Yes)   = {len(play_yes[play_yes['Weather'] == 'Sunny'])}/{len(play_yes)} = {p_sunny_yes:.4f}\")\n",
    "print(f\"   P(High|Yes)    = {len(play_yes[play_yes['Temperature'] == 'High'])}/{len(play_yes)} = {p_high_yes:.4f}\")\n",
    "print(f\"   P(Normal|Yes)  = {len(play_yes[play_yes['Humidity'] == 'Normal'])}/{len(play_yes)} = {p_normal_yes:.4f}\")\n",
    "print(f\"   P(No wind|Yes) = {len(play_yes[play_yes['Wind'] == 'No'])}/{len(play_yes)} = {p_no_wind_yes:.4f}\")\n",
    "\n",
    "print(f\"\\n4. CONDITIONAL PROBABILITIES for Play=No:\")\n",
    "p_sunny_no = len(play_no[play_no['Weather'] == 'Sunny']) / len(play_no)\n",
    "p_high_no = len(play_no[play_no['Temperature'] == 'High']) / len(play_no)\n",
    "p_normal_no = len(play_no[play_no['Humidity'] == 'Normal']) / len(play_no)\n",
    "p_no_wind_no = len(play_no[play_no['Wind'] == 'No']) / len(play_no)\n",
    "\n",
    "print(f\"   P(Sunny|No)   = {len(play_no[play_no['Weather'] == 'Sunny'])}/{len(play_no)} = {p_sunny_no:.4f}\")\n",
    "print(f\"   P(High|No)    = {len(play_no[play_no['Temperature'] == 'High'])}/{len(play_no)} = {p_high_no:.4f}\")\n",
    "print(f\"   P(Normal|No)  = {len(play_no[play_no['Humidity'] == 'Normal'])}/{len(play_no)} = {p_normal_no:.4f}\")\n",
    "print(f\"   P(No wind|No) = {len(play_no[play_no['Wind'] == 'No'])}/{len(play_no)} = {p_no_wind_no:.4f}\")\n",
    "\n",
    "prob_yes = p_yes * p_sunny_yes * p_high_yes * p_normal_yes * p_no_wind_yes\n",
    "prob_no = p_no * p_sunny_no * p_high_no * p_normal_no * p_no_wind_no\n",
    "\n",
    "print(f\"\\n5. NAIVE BAYES CALCULATION:\")\n",
    "print(f\"   P(Yes|X) ∝ {p_yes:.4f} × {p_sunny_yes:.4f} × {p_high_yes:.4f} × {p_normal_yes:.4f} × {p_no_wind_yes:.4f}\")\n",
    "print(f\"           = {prob_yes:.6f}\")\n",
    "print(f\"\\n   P(No|X)  ∝ {p_no:.4f} × {p_sunny_no:.4f} × {p_high_no:.4f} × {p_normal_no:.4f} × {p_no_wind_no:.4f}\")\n",
    "print(f\"           = {prob_no:.6f}\")\n",
    "\n",
    "total_prob = prob_yes + prob_no\n",
    "prob_yes_norm = prob_yes / total_prob\n",
    "prob_no_norm = prob_no / total_prob\n",
    "\n",
    "print(f\"\\n6. NORMALIZED PROBABILITIES:\")\n",
    "print(f\"   P(Yes|X) = {prob_yes:.6f} / {total_prob:.6f} = {prob_yes_norm:.4f} ({prob_yes_norm * 100:.2f}%)\")\n",
    "print(f\"   P(No|X)  = {prob_no:.6f} / {total_prob:.6f} = {prob_no_norm:.4f} ({prob_no_norm * 100:.2f}%)\")\n",
    "\n",
    "prediction_manual = 'Yes' if prob_yes > prob_no else 'No'\n",
    "print(f\"\\n7. PREDICTION: Play = {prediction_manual}\")\n",
    "print(f\"   (Since P(Yes|X) {'>' if prob_yes > prob_no else '<'} P(No|X))\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"SKLEARN IMPLEMENTATION\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "le_dict = {}\n",
    "df_encoded = df.copy()\n",
    "\n",
    "for column in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df_encoded[column] = le.fit_transform(df[column])\n",
    "    le_dict[column] = le\n",
    "\n",
    "X = df_encoded.drop('Play', axis=1).values\n",
    "y = df_encoded['Play'].values\n",
    "\n",
    "nb_model = CategoricalNB()\n",
    "nb_model.fit(X, y)\n",
    "\n",
    "y_pred = nb_model.predict(X)\n",
    "\n",
    "new_instance_encoded = []\n",
    "for col in ['Weather', 'Temperature', 'Humidity', 'Wind']:\n",
    "    value = new_instance[col]\n",
    "    encoded_value = le_dict[col].transform([value])[0]\n",
    "    new_instance_encoded.append(encoded_value)\n",
    "\n",
    "new_instance_array = np.array([new_instance_encoded])\n",
    "prediction_sklearn = nb_model.predict(new_instance_array)[0]\n",
    "probabilities_sklearn = nb_model.predict_proba(new_instance_array)[0]\n",
    "\n",
    "prediction_label = le_dict['Play'].inverse_transform([prediction_sklearn])[0]\n",
    "\n",
    "print(f\"\\nPrediction for new instance: {prediction_label}\")\n",
    "print(f\"Probabilities: No={probabilities_sklearn[0]:.4f}, Yes={probabilities_sklearn[1]:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"CONFUSION MATRIX (Training Data)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"\\n                Predicted\")\n",
    "print(f\"              No      Yes\")\n",
    "print(f\"Actual No     {tn:3d}     {fp:3d}\")\n",
    "print(f\"Actual Yes    {fn:3d}     {tp:3d}\")\n",
    "\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred)\n",
    "recall = recall_score(y, y_pred)\n",
    "f1 = f1_score(y, y_pred)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"PERFORMANCE METRICS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"True Positives (TP):   {tp}\")\n",
    "print(f\"True Negatives (TN):   {tn}\")\n",
    "print(f\"False Positives (FP):  {fp}\")\n",
    "print(f\"False Negatives (FN):  {fn}\")\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy * 100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision * 100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall * 100:.2f}%)\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=axes[0],\n",
    "            xticklabels=['Predicted No', 'Predicted Yes'],\n",
    "            yticklabels=['Actual No', 'Actual Yes'],\n",
    "            annot_kws={\"size\": 16})\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual Class', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Class', fontsize=12)\n",
    "\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "metrics_values = [accuracy, precision, recall, f1]\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#f39c12']\n",
    "\n",
    "bars = axes[1].bar(metrics_names, metrics_values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[1].set_ylabel('Score', fontsize=12)\n",
    "axes[1].set_title('Performance Metrics', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim(0, 1.1)\n",
    "axes[1].axhline(y=1.0, color='gray', linestyle='--', linewidth=1, alpha=0.5)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                 f'{height:.3f}',\n",
    "                 ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"LAPLACE SMOOTHING\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(\"Laplace smoothing prevents zero probabilities when a feature\")\n",
    "print(\"value never appears with a certain class in the training data.\")\n",
    "print(\"\\nFormula: P(x_i|c_j) = (n_ij + 1) / (n_j + c)\")\n",
    "print(\"  where n_ij = count of feature value in class\")\n",
    "print(\"        n_j = total count of class\")\n",
    "print(\"        c = number of classes\")\n",
    "print(\"\\nExample: If 'Windy' weather never appeared with Play=Yes,\")\n",
    "print(\"without smoothing P(Windy|Yes) = 0, making P(Yes|X) = 0\")\n",
    "print(\"With smoothing: P(Windy|Yes) = (0+1)/(9+2) = 0.091\")\n",
    "print(\"\\nThe sklearn CategoricalNB uses alpha parameter for smoothing.\")\n",
    "print(f\"Current model alpha: {nb_model.alpha}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6aab2575",
   "metadata": {},
   "source": [
    "# Temă"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Sarcină:** Rezolvați și prezentați problemele similar cu cele rezolvate la laborator",
   "id": "86595c4ef4223701"
  },
  {
   "cell_type": "markdown",
   "id": "8c6a869d",
   "metadata": {},
   "source": [
    "## Regresie polinomială"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d279c6",
   "metadata": {},
   "source": [
    "Un fermier dorește să prezică randamentul de grâu în funcție de cantitatea de fertilizator utilizată.\n",
    "\n",
    "Date:\n",
    "- Fertilizator (kg/ hectar): `[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]`\n",
    "- Randament (tone/ hectar): `[2.1, 2.8, 3.6, 4.5, 5.2, 5.8, 6.2, 6.4, 6.5, 6.4, 6.2, 5.9, 5.4, 4.8, 4.0]`\n",
    "\n",
    "Notă: prea puțin fertilizator = randament mic; cantitate optimă = randament mare; prea mult = scădere randament.\n",
    "\n",
    "Sarcini:\n",
    "1. Împărțire date în seturi de antrenament (primele 12 puncte) și testare (ultimele 3 puncte)\n",
    "2. Antrenare modele de regresie polinomială (grad 1, 2, 3 și 4)\n",
    "3. Calculare MAE, MSE, RMSE și R<sup>2</sup> atât pentru datele de antrenare cât și testare\n",
    "4. Identificarea cantității optime de fertilizator\n",
    "5. Explicare care grad reprezintă cel mai bine realitatea\n",
    "6. Vizualizarea tuturor modelelor și discutarea overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113d2ccd",
   "metadata": {},
   "source": [
    "## Regresie logistică"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ab7d2",
   "metadata": {},
   "source": [
    "Dorim să prezicem șansele de boală cardiacă în funcție de vârstă și nivel de colesterol.\n",
    "\n",
    "Date:\n",
    "- Vârstă: `[25, 30, 35, 40, 45, 50, 52, 55, 58, 60, 62, 65, 68, 70, 72, 75, 78, 80]`\n",
    "- Colesterol (mg/dL): `[180, 190, 195, 200, 210, 220, 235, 240, 250, 255, 265, 270, 280, 285, 295, 300, 310, 320]`\n",
    "- Boală cardiacă (1=Da, 0=Nu): `[0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]`\n",
    "\n",
    "Sarcini:\n",
    "1. Împărțire date în seturi de antrenament (primele 14 puncte) și testare (ultimele 4 puncte)\n",
    "2. Antrenare model de regresie logistică\n",
    "3. Calcularea tuturor metricilor pentru seturile de date de antrenare și testare\n",
    "4. Vizualizarea funcției de decizie\n",
    "5. Prezicerea probabilității de boală pentru o persoană de 55 de ani cu nivelul de colesterol 260 mg/dl\n",
    "6. Discutarea importanței fiecărui feature (caracteristici)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee288cc3",
   "metadata": {},
   "source": [
    "## Clasificator Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff234b4f",
   "metadata": {},
   "source": [
    "Clasificare email drept spam sau nu bazat pe prezența cuvinetelor.\n",
    "\n",
    "Date:\n",
    "| Email | Conține \"Free\" | Conține \"Money\" | Conține \"Winner\" | Are link | Spam |\n",
    "|-------|----------------|------------------|-------------------|----------|------|\n",
    "| 1 | Da | Da | Da | Da | Da |\n",
    "| 2 | Da | Da | Nu | Da | Da |\n",
    "| 3 | Nu | Nu | Nu | Nu | Nu |\n",
    "| 4 | Da | Nu | Da | Da | Da |\n",
    "| 5 | Nu | Nu | Nu | Da | Nu |\n",
    "| 6 | Da | Da | Da | Da | Da |\n",
    "| 7 | Nu | Da | Nu | Da | Da |\n",
    "| 8 | Nu | Nu | Nu | Nu | Nu |\n",
    "| 9 | Da | Da | Da | Nu | Da |\n",
    "| 10 | Nu | Nu | Da | Nu | Nu |\n",
    "| 11 | Da | Nu | Nu | Da | Da |\n",
    "| 12 | Nu | Nu | Nu | Nu | Nu |\n",
    "| 13 | Da | Da | Da | Da | Da |\n",
    "| 14 | Nu | Da | Da | Da | Da |\n",
    "| 15 | Nu | Nu | Nu | Da | Nu |\n",
    "| 16 | Da | Da | Nu | Da | Da |\n",
    "| 17 | Nu | Nu | Nu | Nu | Nu |\n",
    "| 18 | Da | Nu | Da | Da | Da |\n",
    "| 19 | Nu | Nu | Da | Nu | Da |\n",
    "| 20 | Nu | Nu | Nu | Nu | Nu |\n",
    "\n",
    "Predicție nouă: Vreme=Soare, Temperatură=Mare, Umiditate=Normală, Vânt=Absent\n",
    "\n",
    "Sarcini:\n",
    "1. Împărțire date în seturi de antrenament (primele 16 puncte) și testare (ultimele 4 puncte)\n",
    "2. Calculare manual prior posibility P(Play=Yes) și P(Play=No)\n",
    "3. Calculare manual probabilități condiționale\n",
    "4. Clasificarea unui nou email: `Free=Yes,Money=No,Winner=Yes,HasLink=Yes`\n",
    "5. Antrenare model și comparare rezultate\n",
    "6. Calculare matrice de confuzie și toate metricile atât pentru datele de antrenament cât și de test\n",
    "7. Aplicare Laplace smoothing și observat efecte\n",
    "8. Vizualizare importanță caracteristici (care cuvinte sunt cele mai bune indicatoare pentru spam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
